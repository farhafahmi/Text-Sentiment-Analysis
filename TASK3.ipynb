{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnEYsacu2UxNmUC4w4D/46",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhafahmi/Text-Sentiment-Analysis/blob/main/TASK3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLg0Uj3wNfEn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(rc={'figure.figsize':(30,1)})\n",
        "\n",
        "def visualise_sentiments(data):\n",
        "  sns.heatmap(pd.DataFrame(data).set_index(\"Sentence\").T,center=0, annot=True, cmap = \"PiYG\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"i really like you but you can be so dumb some times\""
      ],
      "metadata": {
        "id": "mIYLC5vVNmsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "IvlqqcFDN7nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sid.polarity_scores(sentence)"
      ],
      "metadata": {
        "id": "j7xjGE69N9_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualise_sentiments({\n",
        "    \"Sentence\":[\"SENTENCE\"] + sentence.split(),\n",
        "    \"Sentiment\":[sid.polarity_scores(sentence)[\"compound\"]] + [sid.polarity_scores(word)[\"compound\"] for word in sentence.split()]\n",
        "})"
      ],
      "metadata": {
        "id": "uAJcxwIyN__t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "DNqSdvqVOBsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TextBlob(sentence).sentiment"
      ],
      "metadata": {
        "id": "xrjywTYMOCzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualise_sentiments({\n",
        "      \"Sentence\":[\"SENTENCE\"] + sentence.split(),\n",
        "      \"Sentiment\":[TextBlob(sentence).polarity] + [TextBlob(word).polarity for word in sentence.split()],\n",
        "      \"Subjectivity\":[TextBlob(sentence).subjectivity] + [TextBlob(word).subjectivity for word in sentence.split()],\n",
        "})"
      ],
      "metadata": {
        "id": "pGRtcRnGODrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install flair\n",
        "import flair\n",
        "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')"
      ],
      "metadata": {
        "id": "OMsUVmU9OGvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = flair.data.Sentence(sentence)\n",
        "flair_sentiment.predict(s)\n",
        "total_sentiment = s.labels\n",
        "total_sentiment"
      ],
      "metadata": {
        "id": "AIOVoc0ROI-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token.text for token in s.tokens]\n",
        "ss = [flair.data.Sentence(s) for s in tokens]\n",
        "[flair_sentiment.predict(s) for s in ss]\n",
        "sentiments = [s.labels[0].score * (-1,1)[str(s.labels[0]).split()[0].startswith(\"POS\")] for s in ss]\n",
        "\n",
        "visualise_sentiments({\n",
        "      \"Sentence\":[\"SENTENCE\"] + tokens,\n",
        "      \"Sentiment\":[total_sentiment[0].score *(-1,1)[str(total_sentiment[0]).split()[0].startswith(\"POS\")]] + sentiments,\n",
        "})"
      ],
      "metadata": {
        "id": "4BZcXT8tOV3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair\n"
      ],
      "metadata": {
        "id": "zsPbWEo3x_7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Import dependencies\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import flair\n",
        "\n",
        "# ✅ Input sentence\n",
        "sentence = \"i really like you but you can be so dumb some times\"\n",
        "\n",
        "# ✅ Initialise VADER\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# ✅ Initialise Flair\n",
        "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')\n",
        "\n",
        "# ✅ Sentence tokens\n",
        "tokens = sentence.split()\n",
        "\n",
        "# ✅ VADER\n",
        "vader_sentiments = [sid.polarity_scores(sentence)[\"compound\"]] + [\n",
        "    sid.polarity_scores(word)[\"compound\"] for word in tokens\n",
        "]\n",
        "\n",
        "# ✅ TextBlob\n",
        "textblob_polarity = [TextBlob(sentence).polarity] + [TextBlob(word).polarity for word in tokens]\n",
        "textblob_subjectivity = [TextBlob(sentence).subjectivity] + [TextBlob(word).subjectivity for word in tokens]\n",
        "\n",
        "# ✅ Flair\n",
        "s = flair.data.Sentence(sentence)\n",
        "flair_sentiment.predict(s)\n",
        "total_sentiment = s.labels\n",
        "ss = [flair.data.Sentence(w) for w in tokens]\n",
        "[flair_sentiment.predict(x) for x in ss]\n",
        "flair_sentiments = [\n",
        "    total_sentiment[0].score * (-1, 1)[str(total_sentiment[0]).split()[0].startswith(\"POS\")]\n",
        "] + [\n",
        "    x.labels[0].score * (-1, 1)[str(x.labels[0]).split()[0].startswith(\"POS\")] for x in ss\n",
        "]\n",
        "\n",
        "# ✅ Combine all\n",
        "df = pd.DataFrame({\n",
        "    \"Word\": [\"SENTENCE\"] + tokens,\n",
        "    \"VADER\": vader_sentiments,\n",
        "    \"TextBlob_Polarity\": textblob_polarity,\n",
        "    \"TextBlob_Subjectivity\": textblob_subjectivity,\n",
        "    \"Flair\": flair_sentiments\n",
        "}).set_index(\"Word\").T\n",
        "\n",
        "# ✅ Visualise\n",
        "sns.set(rc={'figure.figsize':(30, 4)})\n",
        "sns.heatmap(df, annot=True, center=0, cmap=\"PiYG\")\n",
        "plt.title(\"Sentiment Comparison (VADER, TextBlob, Flair)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jZv1npMkxgIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.T.to_csv(\"sentiment_results.csv\")\n",
        "print(\"Saved to sentiment_results.csv\")\n"
      ],
      "metadata": {
        "id": "5wSkUQDwzI6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_sentiments(sentence):\n",
        "    tokens = sentence.split()\n",
        "\n",
        "    vader = [sid.polarity_scores(sentence)[\"compound\"]] + [sid.polarity_scores(w)[\"compound\"] for w in tokens]\n",
        "    tb_pol = [TextBlob(sentence).polarity] + [TextBlob(w).polarity for w in tokens]\n",
        "    tb_sub = [TextBlob(sentence).subjectivity] + [TextBlob(w).subjectivity for w in tokens]\n",
        "\n",
        "    s = flair.data.Sentence(sentence)\n",
        "    flair_sentiment.predict(s)\n",
        "    total = s.labels\n",
        "    ss = [flair.data.Sentence(w) for w in tokens]\n",
        "    [flair_sentiment.predict(x) for x in ss]\n",
        "    flair_s = [total[0].score * (-1, 1)[str(total[0]).split()[0].startswith(\"POS\")]] + [\n",
        "        x.labels[0].score * (-1, 1)[str(x.labels[0]).split()[0].startswith(\"POS\")] for x in ss\n",
        "    ]\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"Word\": [\"SENTENCE\"] + tokens,\n",
        "        \"VADER\": vader,\n",
        "        \"TextBlob_Polarity\": tb_pol,\n",
        "        \"TextBlob_Subjectivity\": tb_sub,\n",
        "        \"Flair\": flair_s\n",
        "    }).set_index(\"Word\").T\n",
        "\n",
        "    sns.set(rc={'figure.figsize':(30, 4)})\n",
        "    sns.heatmap(df, annot=True, center=0, cmap=\"PiYG\")\n",
        "    plt.title(\"Sentiment Comparison\")\n",
        "    plt.show()\n",
        "\n",
        "    return df.T\n"
      ],
      "metadata": {
        "id": "3Bu4xiKjzKB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_sentiments(\"i really like you but you can be so dumb sometimes\")\n"
      ],
      "metadata": {
        "id": "92WCnVm0zX8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}